{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-05T18:13:18.028204Z",
     "start_time": "2026-01-05T18:12:47.619365Z"
    }
   },
   "source": [
    "# ==========================================\n",
    "# AN√ÅLISIS DE CONTRIBUCI√ìN AL AUC POR FEATURE\n",
    "# ==========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "from xgboost import XGBClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üìä AN√ÅLISIS DE IMPORTANCIA DE FEATURES PARA AUC\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ==========================================\n",
    "# 1. CARGAR DATOS\n",
    "# ==========================================\n",
    "print(\"\\nüìÇ Cargando datos...\")\n",
    "\n",
    "df = pd.read_parquet(\"../data/interim/train_final_advanced_features.parquet\")\n",
    "\n",
    "# Limpiar\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "cols_to_drop = [c for c in df.columns if c.endswith('_x') or c.endswith('_y')]\n",
    "df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "X = df.drop(['TARGET', 'SK_ID_CURR'], axis=1, errors='ignore')\n",
    "y = df['TARGET']\n",
    "\n",
    "# Encoding\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "for col in cat_cols:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "X = X.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {X.shape[0]}\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 2. ENTRENAR MODELO BASE\n",
    "# ==========================================\n",
    "print(\"\\nüîß Entrenando modelo base...\")\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=1000,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.02,\n",
    "    min_child_weight=50,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.5,\n",
    "    scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "    device='cuda',\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=100,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "baseline_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "print(f\"AUC Baseline: {baseline_auc:.4f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 3. FEATURE IMPORTANCE DEL MODELO\n",
    "# ==========================================\n",
    "print(\"\\nüìä Calculando Feature Importance del modelo...\")\n",
    "\n",
    "fi_gain = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance_gain': model.feature_importances_\n",
    "}).sort_values('importance_gain', ascending=False)\n",
    "\n",
    "# Normalizar a porcentaje\n",
    "fi_gain['pct_importance'] = fi_gain['importance_gain'] / fi_gain['importance_gain'].sum() * 100\n",
    "\n",
    "print(\"\\nüèÜ TOP 30 Features por Importancia (Gain):\")\n",
    "print(fi_gain.head(30).to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 4. CORRELACI√ìN CON TARGET\n",
    "# ==========================================\n",
    "print(\"\\nüìä Calculando correlaci√≥n con TARGET...\")\n",
    "\n",
    "correlations = []\n",
    "for col in X.columns:\n",
    "    corr = X[col].corr(y)\n",
    "    correlations.append({\n",
    "        'feature': col,\n",
    "        'correlation': corr,\n",
    "        'abs_correlation': abs(corr)\n",
    "    })\n",
    "\n",
    "corr_df = pd.DataFrame(correlations).sort_values('abs_correlation', ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ TOP 30 Features por Correlaci√≥n con TARGET:\")\n",
    "print(corr_df.head(30).to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 5. PERMUTATION IMPORTANCE (Impacto real en AUC)\n",
    "# ==========================================\n",
    "print(\"\\nüìä Calculando Permutation Importance (esto tarda unos minutos)...\")\n",
    "print(\"   Esto mide cu√°nto BAJA el AUC cuando se permuta cada feature...\")\n",
    "\n",
    "# Usar subset para velocidad\n",
    "sample_idx = np.random.choice(len(X_test), min(10000, len(X_test)), replace=False)\n",
    "X_test_sample = X_test.iloc[sample_idx]\n",
    "y_test_sample = y_test.iloc[sample_idx]\n",
    "\n",
    "perm_importance = permutation_importance(\n",
    "    model, X_test_sample, y_test_sample,\n",
    "    n_repeats=5,\n",
    "    random_state=42,\n",
    "    scoring='roc_auc',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "perm_df = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'perm_importance_mean': perm_importance.importances_mean,\n",
    "    'perm_importance_std': perm_importance.importances_std\n",
    "}).sort_values('perm_importance_mean', ascending=False)\n",
    "\n",
    "# Convertir a \"p√©rdida de AUC\"\n",
    "perm_df['auc_drop'] = perm_df['perm_importance_mean']\n",
    "perm_df['auc_drop_pct'] = perm_df['auc_drop'] / baseline_auc * 100\n",
    "\n",
    "print(\"\\nüèÜ TOP 30 Features por Permutation Importance:\")\n",
    "print(\"   (Cu√°nto BAJA el AUC si se elimina la informaci√≥n de esa feature)\")\n",
    "print(perm_df[['feature', 'auc_drop', 'auc_drop_pct']].head(30).to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 6. DROP COLUMN IMPORTANCE (Top 50 features)\n",
    "# ==========================================\n",
    "print(\"\\nüìä Calculando Drop Column Importance (Top 50 features)...\")\n",
    "print(\"   Esto entrena el modelo SIN cada feature y mide la ca√≠da en AUC...\")\n",
    "\n",
    "top_features = fi_gain.head(50)['feature'].tolist()\n",
    "drop_importance = []\n",
    "\n",
    "for i, feat in enumerate(top_features):\n",
    "    print(f\"   Procesando {i+1}/50: {feat}...\", end='\\r')\n",
    "\n",
    "    # Entrenar sin esta feature\n",
    "    X_train_drop = X_train.drop(columns=[feat])\n",
    "    X_test_drop = X_test.drop(columns=[feat])\n",
    "\n",
    "    model_drop = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        max_depth=5,\n",
    "        learning_rate=0.03,\n",
    "        min_child_weight=50,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.5,\n",
    "        scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum(),\n",
    "        device='cuda',\n",
    "        tree_method='hist',\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model_drop.fit(X_train_drop, y_train)\n",
    "\n",
    "    auc_without = roc_auc_score(y_test, model_drop.predict_proba(X_test_drop)[:, 1])\n",
    "    auc_drop = baseline_auc - auc_without\n",
    "\n",
    "    drop_importance.append({\n",
    "        'feature': feat,\n",
    "        'auc_with': baseline_auc,\n",
    "        'auc_without': auc_without,\n",
    "        'auc_drop': auc_drop,\n",
    "        'auc_drop_pct': auc_drop / baseline_auc * 100\n",
    "    })\n",
    "\n",
    "print(\"\\n\")\n",
    "drop_df = pd.DataFrame(drop_importance).sort_values('auc_drop', ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ TOP 30 Features por Drop Column Importance:\")\n",
    "print(\"   (Cu√°nto BAJA el AUC si se ELIMINA completamente esa feature)\")\n",
    "print(drop_df.head(30).to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 7. AN√ÅLISIS COMBINADO\n",
    "# ==========================================\n",
    "print(\"\\nüìä Creando an√°lisis combinado...\")\n",
    "\n",
    "# Merge all importance metrics\n",
    "combined = fi_gain[['feature', 'importance_gain', 'pct_importance']].copy()\n",
    "combined = combined.merge(corr_df[['feature', 'correlation', 'abs_correlation']], on='feature', how='left')\n",
    "combined = combined.merge(perm_df[['feature', 'auc_drop', 'auc_drop_pct']], on='feature', how='left')\n",
    "combined = combined.merge(drop_df[['feature', 'auc_drop']].rename(columns={'auc_drop': 'drop_auc_impact'}),\n",
    "                          on='feature', how='left')\n",
    "\n",
    "# Calcular score combinado\n",
    "combined['combined_score'] = (\n",
    "    combined['pct_importance'].fillna(0) * 0.3 +\n",
    "    combined['abs_correlation'].fillna(0) * 100 * 0.2 +\n",
    "    combined['auc_drop_pct'].fillna(0) * 0.3 +\n",
    "    combined['drop_auc_impact'].fillna(0) * 1000 * 0.2\n",
    ")\n",
    "\n",
    "combined = combined.sort_values('combined_score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üèÜ RANKING FINAL DE FEATURES (Score Combinado)\")\n",
    "print(\"=\"*80)\n",
    "print(combined.head(40).to_string(index=False))\n",
    "\n",
    "# ==========================================\n",
    "# 8. AN√ÅLISIS POR CATEGOR√çA\n",
    "# ==========================================\n",
    "print(\"\\nüìä An√°lisis por categor√≠a de features...\")\n",
    "\n",
    "def get_category(feature_name):\n",
    "    if 'EXT' in feature_name.upper():\n",
    "        return 'EXT_SOURCE'\n",
    "    elif 'BUREAU' in feature_name.upper():\n",
    "        return 'BUREAU'\n",
    "    elif 'PREV' in feature_name.upper():\n",
    "        return 'PREVIOUS'\n",
    "    elif 'INST' in feature_name.upper():\n",
    "        return 'INSTALLMENTS'\n",
    "    elif 'POS' in feature_name.upper():\n",
    "        return 'POS_CASH'\n",
    "    elif 'CC_' in feature_name.upper():\n",
    "        return 'CREDIT_CARD'\n",
    "    elif 'AMT_' in feature_name.upper():\n",
    "        return 'FINANCIAL'\n",
    "    elif 'DAYS_' in feature_name.upper():\n",
    "        return 'TEMPORAL'\n",
    "    elif 'RISK' in feature_name.upper():\n",
    "        return 'RISK_SCORE'\n",
    "    elif any(x in feature_name.upper() for x in ['AGE', 'EMPLOY', 'WORK']):\n",
    "        return 'DEMOGRAPHIC'\n",
    "    else:\n",
    "        return 'OTHER'\n",
    "\n",
    "combined['category'] = combined['feature'].apply(get_category)\n",
    "\n",
    "category_summary = combined.groupby('category').agg({\n",
    "    'feature': 'count',\n",
    "    'pct_importance': 'sum',\n",
    "    'auc_drop_pct': 'sum',\n",
    "    'combined_score': 'sum'\n",
    "}).rename(columns={'feature': 'num_features'})\n",
    "\n",
    "category_summary = category_summary.sort_values('pct_importance', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä IMPORTANCIA POR CATEGOR√çA\")\n",
    "print(\"=\"*60)\n",
    "print(category_summary.to_string())\n",
    "\n",
    "# ==========================================\n",
    "# 9. VISUALIZACIONES\n",
    "# ==========================================\n",
    "print(\"\\nüìä Generando visualizaciones...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 14))\n",
    "\n",
    "# 9.1 Top 20 por Gain Importance\n",
    "top20_gain = fi_gain.head(20)\n",
    "axes[0, 0].barh(range(len(top20_gain)), top20_gain['pct_importance'], color='steelblue')\n",
    "axes[0, 0].set_yticks(range(len(top20_gain)))\n",
    "axes[0, 0].set_yticklabels(top20_gain['feature'], fontsize=8)\n",
    "axes[0, 0].invert_yaxis()\n",
    "axes[0, 0].set_xlabel('% Importancia')\n",
    "axes[0, 0].set_title('Top 20 Features - Gain Importance', fontweight='bold')\n",
    "\n",
    "# 9.2 Top 20 por Correlaci√≥n\n",
    "top20_corr = corr_df.head(20)\n",
    "colors = ['green' if c < 0 else 'red' for c in top20_corr['correlation']]\n",
    "axes[0, 1].barh(range(len(top20_corr)), top20_corr['correlation'], color=colors)\n",
    "axes[0, 1].set_yticks(range(len(top20_corr)))\n",
    "axes[0, 1].set_yticklabels(top20_corr['feature'], fontsize=8)\n",
    "axes[0, 1].invert_yaxis()\n",
    "axes[0, 1].set_xlabel('Correlaci√≥n con TARGET')\n",
    "axes[0, 1].set_title('Top 20 Features - Correlaci√≥n', fontweight='bold')\n",
    "axes[0, 1].axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "\n",
    "# 9.3 Top 20 por Permutation Importance\n",
    "top20_perm = perm_df.head(20)\n",
    "axes[0, 2].barh(range(len(top20_perm)), top20_perm['auc_drop_pct'], color='coral')\n",
    "axes[0, 2].set_yticks(range(len(top20_perm)))\n",
    "axes[0, 2].set_yticklabels(top20_perm['feature'], fontsize=8)\n",
    "axes[0, 2].invert_yaxis()\n",
    "axes[0, 2].set_xlabel('% Ca√≠da de AUC al permutar')\n",
    "axes[0, 2].set_title('Top 20 Features - Permutation Importance', fontweight='bold')\n",
    "\n",
    "# 9.4 Top 20 por Drop Column\n",
    "top20_drop = drop_df.head(20)\n",
    "axes[1, 0].barh(range(len(top20_drop)), top20_drop['auc_drop'] * 1000, color='purple')\n",
    "axes[1, 0].set_yticks(range(len(top20_drop)))\n",
    "axes[1, 0].set_yticklabels(top20_drop['feature'], fontsize=8)\n",
    "axes[1, 0].invert_yaxis()\n",
    "axes[1, 0].set_xlabel('Ca√≠da de AUC x1000')\n",
    "axes[1, 0].set_title('Top 20 Features - Drop Column Impact', fontweight='bold')\n",
    "\n",
    "# 9.5 Importancia por Categor√≠a\n",
    "cat_colors = plt.cm.Set3(range(len(category_summary)))\n",
    "axes[1, 1].pie(category_summary['pct_importance'], labels=category_summary.index,\n",
    "               autopct='%1.1f%%', colors=cat_colors)\n",
    "axes[1, 1].set_title('Distribuci√≥n de Importancia por Categor√≠a', fontweight='bold')\n",
    "\n",
    "# 9.6 Top 20 Combined Score\n",
    "top20_combined = combined.head(20)\n",
    "axes[1, 2].barh(range(len(top20_combined)), top20_combined['combined_score'], color='teal')\n",
    "axes[1, 2].set_yticks(range(len(top20_combined)))\n",
    "axes[1, 2].set_yticklabels(top20_combined['feature'], fontsize=8)\n",
    "axes[1, 2].invert_yaxis()\n",
    "axes[1, 2].set_xlabel('Score Combinado')\n",
    "axes[1, 2].set_title('Top 20 Features - Score Combinado', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/feature_importance_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Visualizaciones guardadas en '../reports/figures/feature_importance_analysis.png'\")\n",
    "\n",
    "# ==========================================\n",
    "# 10. RECOMENDACIONES\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üí° RECOMENDACIONES PARA MEJORAR EL AUC\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Top features por cada categor√≠a\n",
    "print(\"\\nüéØ TOP 5 FEATURES M√ÅS IMPORTANTES:\")\n",
    "for i, row in combined.head(5).iterrows():\n",
    "    print(f\"   {row['feature']}: {row['pct_importance']:.2f}% importancia, \"\n",
    "          f\"corr={row['correlation']:.4f}, drop_impact={row.get('drop_auc_impact', 0):.4f}\")\n",
    "\n",
    "# Features con alta correlaci√≥n pero baja importancia (oportunidad)\n",
    "high_corr_low_imp = combined[\n",
    "    (combined['abs_correlation'] > 0.05) &\n",
    "    (combined['pct_importance'] < 0.5)\n",
    "].head(10)\n",
    "\n",
    "print(\"\\nüîç OPORTUNIDADES (alta correlaci√≥n, baja importancia actual):\")\n",
    "print(\"   Estas features tienen informaci√≥n √∫til pero el modelo no las usa bien:\")\n",
    "for _, row in high_corr_low_imp.iterrows():\n",
    "    print(f\"   - {row['feature']}: corr={row['correlation']:.4f}, imp={row['pct_importance']:.2f}%\")\n",
    "\n",
    "# Categor√≠as subexplotadas\n",
    "print(\"\\nüìä CATEGOR√çAS CON POTENCIAL DE MEJORA:\")\n",
    "for cat, data in category_summary.iterrows():\n",
    "    if data['pct_importance'] < 10 and data['num_features'] > 5:\n",
    "        print(f\"   - {cat}: {data['num_features']} features pero solo {data['pct_importance']:.1f}% de importancia\")\n",
    "\n",
    "# Guardar an√°lisis\n",
    "combined.to_csv('../reports/feature_importance_analysis.csv', index=False)\n",
    "category_summary.to_csv('../reports/category_importance.csv')\n",
    "\n",
    "print(\"\\nüíæ An√°lisis guardado en '../reports/'\")\n",
    "\n",
    "# ==========================================\n",
    "# 11. RESUMEN EJECUTIVO\n",
    "# ==========================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã RESUMEN EJECUTIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìä DISTRIBUCI√ìN DE IMPORTANCIA:\n",
    "\n",
    "   EXT_SOURCE features: {category_summary.loc['EXT_SOURCE', 'pct_importance']:.1f}% del total\n",
    "   ‚îú‚îÄ‚îÄ Estas son las M√ÅS IMPORTANTES\n",
    "   ‚îú‚îÄ‚îÄ EXT_SOURCE_2 tiene la mayor correlaci√≥n negativa con default\n",
    "   ‚îî‚îÄ‚îÄ Mejorar las combinaciones de EXT_SOURCE podr√≠a dar +0.01 AUC\n",
    "\n",
    "   BUREAU features: {category_summary.loc['BUREAU', 'pct_importance'] if 'BUREAU' in category_summary.index else 0:.1f}%\n",
    "   ‚îú‚îÄ‚îÄ Historial crediticio en otros bancos\n",
    "   ‚îî‚îÄ‚îÄ bureau_dpd_count, bureau_credit_active son clave\n",
    "\n",
    "   INSTALLMENTS features: {category_summary.loc['INSTALLMENTS', 'pct_importance'] if 'INSTALLMENTS' in category_summary.index else 0:.1f}%\n",
    "   ‚îú‚îÄ‚îÄ Comportamiento de pago de cuotas\n",
    "   ‚îî‚îÄ‚îÄ inst_late_ratio es muy predictiva\n",
    "\n",
    "üéØ PARA SUBIR EL AUC, ENF√ìCATE EN:\n",
    "\n",
    "   1. EXT_SOURCE: Ya las estamos usando bien, pero crear m√°s interacciones\n",
    "   2. BUREAU: A√±adir m√°s features de bureau_balance a nivel mensual\n",
    "   3. INSTALLMENTS: Crear features de tendencia m√°s sofisticadas\n",
    "   4. RISK_SCORE: El score compuesto de riesgo es muy √∫til\n",
    "\n",
    "üìà ESTIMACI√ìN DE POTENCIAL:\n",
    "   - Features actuales bien optimizadas: ~0.79 AUC (donde estamos)\n",
    "   - Con features adicionales de bureau_balance: +0.005-0.01\n",
    "   - Con mejor feature engineering de EXT_SOURCE: +0.002-0.005\n",
    "   - Techo estimado con estos datos: ~0.80-0.81 AUC\n",
    "\"\"\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìä AN√ÅLISIS DE IMPORTANCIA DE FEATURES PARA AUC\n",
      "============================================================\n",
      "\n",
      "üìÇ Cargando datos...\n",
      "Features: 215\n",
      "Samples: 307511\n",
      "\n",
      "üîß Entrenando modelo base...\n",
      "AUC Baseline: 0.7850\n",
      "\n",
      "üìä Calculando Feature Importance del modelo...\n",
      "\n",
      "üèÜ TOP 30 Features por Importancia (Gain):\n",
      "                      feature  importance_gain  pct_importance\n",
      "                 EXT_SOURCE_2         0.039387        3.938742\n",
      "                 EXT_SOURCE_3         0.031698        3.169776\n",
      "               FLAG_EMP_PHONE         0.019440        1.944029\n",
      "       inst_last_3_late_ratio         0.018097        1.809686\n",
      "deterioration_composite_score         0.016123        1.612298\n",
      "          NAME_EDUCATION_TYPE         0.015464        1.546442\n",
      "                  CODE_GENDER         0.014937        1.493745\n",
      "  prev_weighted_refused_ratio         0.013994        1.399392\n",
      "               cc_util_recent         0.013962        1.396237\n",
      "                 EXT_SOURCE_1         0.013959        1.395889\n",
      "         pos_recent_count_dpd         0.013674        1.367404\n",
      "              inst_late_trend         0.012651        1.265125\n",
      "        inst_late_ratio_total         0.011834        1.183416\n",
      "              FLAG_DOCUMENT_3         0.011240        1.124001\n",
      "           cc_balance_growing         0.011190        1.119015\n",
      "  bureau_debt_to_credit_ratio         0.010744        1.074442\n",
      "                 FLAG_OWN_CAR         0.009166        0.916637\n",
      "             NAME_INCOME_TYPE         0.009061        0.906064\n",
      "                   DAYS_BIRTH         0.008835        0.883482\n",
      "        bureau_type_Microloan         0.008545        0.854459\n",
      "       REG_CITY_NOT_LIVE_CITY         0.008241        0.824091\n",
      "           inst_late_ratio_1y         0.008117        0.811742\n",
      "   recent_rejection_intensity         0.007771        0.777089\n",
      "           cc_util_historical         0.007633        0.763311\n",
      "              pos_dpd_std_12m         0.007624        0.762426\n",
      "      bureau_days_credit_mean         0.007570        0.757047\n",
      "             pos_dpd_mean_12m         0.007479        0.747930\n",
      "       bureau_new_credits_12m         0.007288        0.728824\n",
      "    prev_recent_refused_count         0.007183        0.718290\n",
      "                DAYS_EMPLOYED         0.007091        0.709112\n",
      "\n",
      "üìä Calculando correlaci√≥n con TARGET...\n",
      "\n",
      "üèÜ TOP 30 Features por Correlaci√≥n con TARGET:\n",
      "                    feature  correlation  abs_correlation\n",
      "               EXT_SOURCE_2    -0.159030         0.159030\n",
      "               EXT_SOURCE_3    -0.119572         0.119572\n",
      "    bureau_days_credit_mean     0.080680         0.080680\n",
      "                 DAYS_BIRTH     0.078239         0.078239\n",
      "prev_weighted_refused_ratio     0.077972         0.077972\n",
      "     bureau_days_credit_min     0.072869         0.072869\n",
      "      inst_late_ratio_total     0.070507         0.070507\n",
      "     bureau_new_credits_12m     0.069967         0.069967\n",
      "         inst_late_ratio_1y     0.068837         0.068837\n",
      "     inst_last_3_late_ratio     0.067031         0.067031\n",
      "      bureau_new_credits_6m     0.066517         0.066517\n",
      "               prev_refused     0.064756         0.064756\n",
      "               EXT_SOURCE_1    -0.064698         0.064698\n",
      " recent_rejection_intensity     0.064577         0.064577\n",
      " inst_partial_payment_ratio     0.063136         0.063136\n",
      "REGION_RATING_CLIENT_W_CITY     0.060893         0.060893\n",
      "         cc_balance_growing     0.060259         0.060259\n",
      "       REGION_RATING_CLIENT     0.058899         0.058899\n",
      "  prev_recent_refused_count     0.056290         0.056290\n",
      "         recent_loans_count     0.055438         0.055438\n",
      "     DAYS_LAST_PHONE_CHANGE     0.055217         0.055217\n",
      "        NAME_EDUCATION_TYPE     0.054699         0.054699\n",
      "                CODE_GENDER     0.054692         0.054692\n",
      "           inst_late_recent     0.053613         0.053613\n",
      "              inst_late_mid     0.053403         0.053403\n",
      "            DAYS_ID_PUBLISH     0.051457         0.051457\n",
      "     REG_CITY_NOT_WORK_CITY     0.050994         0.050994\n",
      "             cc_utilization     0.048523         0.048523\n",
      "            cc_balance_mean     0.048523         0.048523\n",
      "           NAME_INCOME_TYPE     0.046829         0.046829\n",
      "\n",
      "üìä Calculando Permutation Importance (esto tarda unos minutos)...\n",
      "   Esto mide cu√°nto BAJA el AUC cuando se permuta cada feature...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ExecutorManagerThread:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\psutil\\_pswindows.py\", line 692, in wrapper\n",
      "    return fun(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\psutil\\_pswindows.py\", line 870, in kill\n",
      "    return cext.proc_kill(self.pid)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "PermissionError: [WinError 5] Acceso denegado: '(originated from OpenProcess)'\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\usuario\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 635, in run\n",
      "    self.flag_executor_shutting_down()\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 856, in flag_executor_shutting_down\n",
      "    self.kill_workers(reason=\"executor shutting down\")\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 866, in kill_workers\n",
      "    kill_process_tree(p)\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\utils.py\", line 19, in kill_process_tree\n",
      "    _kill_process_tree_with_psutil(process)\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\utils.py\", line 43, in _kill_process_tree_with_psutil\n",
      "    descendant.kill()\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\psutil\\__init__.py\", line 1341, in kill\n",
      "    self._proc.kill()\n",
      "  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\psutil\\_pswindows.py\", line 694, in wrapper\n",
      "    raise convert_oserror(err, pid=self.pid, name=self._name) from err\n",
      "psutil.AccessDenied: (pid=24656)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "parallel_for: failed to synchronize: cudaErrorLaunchFailure: unspecified launch failure",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31m_RemoteTraceback\u001B[39m                          Traceback (most recent call last)",
      "\u001B[31m_RemoteTraceback\u001B[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 459, in _score\n    y_pred = method_caller(clf, \"decision_function\", X, pos_label=pos_label)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n    result, _ = _get_response_values(\n                ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 181, in _get_response_values\n    prediction_method = _check_response_method(estimator, response_method)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1939, in _check_response_method\n    raise AttributeError(\nAttributeError: XGBClassifier has none of the following attributes: decision_function.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 490, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py\", line 607, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 127, in __call__\n    return self.function(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py\", line 70, in _calculate_permutation_scores\n    scores.append(_weights_scorer(scorer, estimator, X_permuted, y, sample_weight))\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py\", line 25, in _weights_scorer\n    return scorer(estimator, X, y)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 266, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 466, in _score\n    y_pred = method_caller(clf, \"predict_proba\", X, pos_label=pos_label)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 86, in _cached_call\n    result, _ = _get_response_values(\n                ^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 194, in _get_response_values\n    y_pred = prediction_method(X)\n             ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1921, in predict_proba\n    class_probs = super().predict(\n                  ^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1446, in predict\n    predts = self.get_booster().inplace_predict(\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 774, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 2887, in inplace_predict\n    _check_call(\n  File \"C:\\Users\\usuario\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 323, in _check_call\n    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\nxgboost.core.XGBoostError: parallel_for: failed to synchronize: cudaErrorLaunchFailure: unspecified launch failure\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mXGBoostError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 123\u001B[39m\n\u001B[32m    120\u001B[39m X_test_sample = X_test.iloc[sample_idx]\n\u001B[32m    121\u001B[39m y_test_sample = y_test.iloc[sample_idx]\n\u001B[32m--> \u001B[39m\u001B[32m123\u001B[39m perm_importance = \u001B[43mpermutation_importance\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    124\u001B[39m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_test_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_test_sample\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    125\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_repeats\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    126\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrandom_state\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m42\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    127\u001B[39m \u001B[43m    \u001B[49m\u001B[43mscoring\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mroc_auc\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    128\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[32;43m1\u001B[39;49m\n\u001B[32m    129\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m    131\u001B[39m perm_df = pd.DataFrame({\n\u001B[32m    132\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mfeature\u001B[39m\u001B[33m'\u001B[39m: X_train.columns,\n\u001B[32m    133\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mperm_importance_mean\u001B[39m\u001B[33m'\u001B[39m: perm_importance.importances_mean,\n\u001B[32m    134\u001B[39m     \u001B[33m'\u001B[39m\u001B[33mperm_importance_std\u001B[39m\u001B[33m'\u001B[39m: perm_importance.importances_std\n\u001B[32m    135\u001B[39m }).sort_values(\u001B[33m'\u001B[39m\u001B[33mperm_importance_mean\u001B[39m\u001B[33m'\u001B[39m, ascending=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    137\u001B[39m \u001B[38;5;66;03m# Convertir a \"p√©rdida de AUC\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    208\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    209\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    210\u001B[39m         skip_parameter_validation=(\n\u001B[32m    211\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    212\u001B[39m         )\n\u001B[32m    213\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m214\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    215\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    216\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    217\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    218\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    219\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    220\u001B[39m     msg = re.sub(\n\u001B[32m    221\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    222\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    223\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    224\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\inspection\\_permutation_importance.py:289\u001B[39m, in \u001B[36mpermutation_importance\u001B[39m\u001B[34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001B[39m\n\u001B[32m    285\u001B[39m     scorer = _MultimetricScorer(scorers=scorers_dict)\n\u001B[32m    287\u001B[39m baseline_score = _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001B[32m--> \u001B[39m\u001B[32m289\u001B[39m scores = \u001B[43mParallel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    290\u001B[39m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_calculate_permutation_scores\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    291\u001B[39m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    292\u001B[39m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    293\u001B[39m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    295\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcol_idx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    296\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    297\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_repeats\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    298\u001B[39m \u001B[43m        \u001B[49m\u001B[43mscorer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    299\u001B[39m \u001B[43m        \u001B[49m\u001B[43mmax_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    300\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    301\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcol_idx\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mrange\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m.\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    302\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    304\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(baseline_score, \u001B[38;5;28mdict\u001B[39m):\n\u001B[32m    305\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m    306\u001B[39m         name: _create_importances_bunch(\n\u001B[32m    307\u001B[39m             baseline_score[name],\n\u001B[32m   (...)\u001B[39m\u001B[32m    311\u001B[39m         \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m baseline_score\n\u001B[32m    312\u001B[39m     }\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m     60\u001B[39m config = get_config()\n\u001B[32m     61\u001B[39m iterable_with_config = (\n\u001B[32m     62\u001B[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[32m     63\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[32m     64\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m65\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001B[39m, in \u001B[36mParallel.__call__\u001B[39m\u001B[34m(self, iterable)\u001B[39m\n\u001B[32m   2066\u001B[39m \u001B[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001B[39;00m\n\u001B[32m   2067\u001B[39m \u001B[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001B[39;00m\n\u001B[32m   2068\u001B[39m \u001B[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001B[39;00m\n\u001B[32m   2069\u001B[39m \u001B[38;5;66;03m# dispatch of the tasks to the workers.\u001B[39;00m\n\u001B[32m   2070\u001B[39m \u001B[38;5;28mnext\u001B[39m(output)\n\u001B[32m-> \u001B[39m\u001B[32m2072\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m output \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.return_generator \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001B[39m, in \u001B[36mParallel._get_outputs\u001B[39m\u001B[34m(self, iterator, pre_dispatch)\u001B[39m\n\u001B[32m   1679\u001B[39m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[32m   1681\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backend.retrieval_context():\n\u001B[32m-> \u001B[39m\u001B[32m1682\u001B[39m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m._retrieve()\n\u001B[32m   1684\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mGeneratorExit\u001B[39;00m:\n\u001B[32m   1685\u001B[39m     \u001B[38;5;66;03m# The generator has been garbage collected before being fully\u001B[39;00m\n\u001B[32m   1686\u001B[39m     \u001B[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001B[39;00m\n\u001B[32m   1687\u001B[39m     \u001B[38;5;66;03m# the user if necessary.\u001B[39;00m\n\u001B[32m   1688\u001B[39m     \u001B[38;5;28mself\u001B[39m._exception = \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1784\u001B[39m, in \u001B[36mParallel._retrieve\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1778\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28mself\u001B[39m._wait_retrieval():\n\u001B[32m   1779\u001B[39m     \u001B[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001B[39;00m\n\u001B[32m   1780\u001B[39m     \u001B[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001B[39;00m\n\u001B[32m   1781\u001B[39m     \u001B[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001B[39;00m\n\u001B[32m   1782\u001B[39m     \u001B[38;5;66;03m# worker traceback.\u001B[39;00m\n\u001B[32m   1783\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._aborting:\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_raise_error_fast\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1785\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m   1787\u001B[39m     nb_jobs = \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m._jobs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1859\u001B[39m, in \u001B[36mParallel._raise_error_fast\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1855\u001B[39m \u001B[38;5;66;03m# If this error job exists, immediately raise the error by\u001B[39;00m\n\u001B[32m   1856\u001B[39m \u001B[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001B[39;00m\n\u001B[32m   1857\u001B[39m \u001B[38;5;66;03m# called directly or if the generator is gc'ed.\u001B[39;00m\n\u001B[32m   1858\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m error_job \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1859\u001B[39m     \u001B[43merror_job\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_result\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py:758\u001B[39m, in \u001B[36mBatchCompletionCallBack.get_result\u001B[39m\u001B[34m(self, timeout)\u001B[39m\n\u001B[32m    752\u001B[39m backend = \u001B[38;5;28mself\u001B[39m.parallel._backend\n\u001B[32m    754\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m backend.supports_retrieve_callback:\n\u001B[32m    755\u001B[39m     \u001B[38;5;66;03m# We assume that the result has already been retrieved by the\u001B[39;00m\n\u001B[32m    756\u001B[39m     \u001B[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001B[39;00m\n\u001B[32m    757\u001B[39m     \u001B[38;5;66;03m# be returned.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m758\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_return_or_raise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    760\u001B[39m \u001B[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001B[39;00m\n\u001B[32m    761\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\Desktop\\4geeks\\Final_Proyect_Credit_Default_Risk-main\\.venv\\Lib\\site-packages\\joblib\\parallel.py:773\u001B[39m, in \u001B[36mBatchCompletionCallBack._return_or_raise\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    771\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    772\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.status == TASK_ERROR:\n\u001B[32m--> \u001B[39m\u001B[32m773\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m._result\n\u001B[32m    774\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._result\n\u001B[32m    775\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "\u001B[31mXGBoostError\u001B[39m: parallel_for: failed to synchronize: cudaErrorLaunchFailure: unspecified launch failure"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a1a65104755ffdf0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
